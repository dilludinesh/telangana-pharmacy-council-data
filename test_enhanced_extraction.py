import json
from responsible_scraper import ResponsibleScraper

def test_enhanced_extraction():
    """Test the enhanced extraction with a few registration numbers"""

    # Load some test registration numbers
    with open('pharmacists_data.json', 'r') as f:
        basic_data = json.load(f)

    # Test with first 5 registration numbers
    test_reg_numbers = [p['registration_number'] for p in basic_data[:5]]

    scraper = ResponsibleScraper()

    print("ğŸ§ª TESTING ENHANCED EXTRACTION")
    print(f"ğŸ“‹ Testing with {len(test_reg_numbers)} registration numbers:")
    for reg in test_reg_numbers:
        print(f"   - {reg}")
    print()

    # Test each one
    for i, reg_number in enumerate(test_reg_numbers):
        print(f"ğŸ” Testing {i+1}/{len(test_reg_numbers)}: {reg_number}")

        detailed_info = scraper.extract_detailed_info(reg_number)

        if detailed_info and detailed_info.get('search_status') == 'success':
            print("   âœ… SUCCESS!")
            print(f"   ğŸ“‹ Name: {detailed_info.get('name', 'N/A')}")
            print(f"   ğŸ‘¨ Father: {detailed_info.get('fathers_name', 'N/A')}")
            print(f"   âš¥ Gender: {detailed_info.get('gender', 'N/A')}")
            print(f"   ğŸ“… Validity: {detailed_info.get('validity', 'N/A')}")
            print(f"   ğŸ¥ Status: {detailed_info.get('status', 'N/A')}")
            print(f"   ğŸ“ Education: {detailed_info.get('college_name', 'N/A')}")
            print(f"   ğŸ“ Address: {detailed_info.get('address', 'N/A')}")
        else:
            print("   âŒ No data found or error occurred")
            print(f"   ğŸ“Š Status: {detailed_info.get('search_status', 'unknown') if detailed_info else 'failed'}")

        print()

    print("ğŸ‰ Test completed!")

if __name__ == "__main__":
    test_enhanced_extraction()
